{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4ff0c2",
   "metadata": {},
   "source": [
    "# 使用普通神经网络包含节点特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1333be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f566fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\".\", name=\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c54285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "1\n",
      "2708\n",
      "1433\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(dataset)\n",
    "print(len(dataset))\n",
    "print(data.x.shape[0])\n",
    "print(dataset.num_features)\n",
    "print(dataset.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6df02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual loading of FacebookPagePage dataset to avoid HTTP 404 error\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_facebook_dataset(root_path=\"FacebookPagePage\"):\n",
    "    \"\"\"\n",
    "    Manually load the Facebook Page-Page dataset from local files\n",
    "    \"\"\"\n",
    "    # Load edges\n",
    "    edges_df = pd.read_csv(f\"{root_path}/raw/musae_facebook_edges.csv\")\n",
    "    edge_index = torch.tensor(edges_df.values.T, dtype=torch.long)\n",
    "    \n",
    "    # Load targets (labels)\n",
    "    targets_df = pd.read_csv(f\"{root_path}/raw/musae_facebook_target.csv\")\n",
    "    \n",
    "    # Encode page_type as numerical labels\n",
    "    le = LabelEncoder()\n",
    "    y = torch.tensor(le.fit_transform(targets_df['page_type']), dtype=torch.long)\n",
    "    \n",
    "    print(f\"Classes: {list(le.classes_)}\")\n",
    "    print(f\"Number of nodes: {len(targets_df)}\")\n",
    "    print(f\"Number of edges: {len(edges_df)}\")\n",
    "    \n",
    "    # Load features (this might take a moment due to file size)\n",
    "    print(\"Loading node features...\")\n",
    "    with open(f\"{root_path}/raw/musae_facebook_features.json\", 'r') as f:\n",
    "        features_dict = json.load(f)\n",
    "    \n",
    "    # Convert features to tensor\n",
    "    # Features are stored as sparse format, we need to create dense feature matrix\n",
    "    num_nodes = len(targets_df)\n",
    "    \n",
    "    # Find the maximum feature index to determine feature dimension\n",
    "    all_feature_indices = []\n",
    "    for node_features in features_dict.values():\n",
    "        all_feature_indices.extend(node_features)\n",
    "    \n",
    "    max_feature_idx = max(all_feature_indices) if all_feature_indices else 0\n",
    "    feature_dim = max_feature_idx + 1\n",
    "    \n",
    "    # Create dense feature matrix\n",
    "    x = torch.zeros((num_nodes, feature_dim), dtype=torch.float)\n",
    "    \n",
    "    for node_id, feature_indices in features_dict.items():\n",
    "        node_idx = int(node_id)\n",
    "        x[node_idx, feature_indices] = 1.0\n",
    "    \n",
    "    print(f\"Feature dimension: {feature_dim}\")\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Add dataset info\n",
    "    data.num_classes = len(le.classes_)\n",
    "    data.num_features = feature_dim\n",
    "    data.class_names = list(le.classes_)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0326292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['company', 'government', 'politician', 'tvshow']\n",
      "Number of nodes: 22470\n",
      "Number of edges: 171002\n",
      "Loading node features...\n",
      "Feature dimension: 4714\n"
     ]
    }
   ],
   "source": [
    "data = load_facebook_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ce830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb329ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e91c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_x = pd.DataFrame(data.x.numpy())\n",
    "df_x['label'] = pd.DataFrame(data.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f2e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d8e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = Linear(dim_in, dim_h)\n",
    "        self.linear2 = Linear(dim_h, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask],data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "            \n",
    "\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e90cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3193a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1.9583, Acc: 0.1429, Val Loss: 1.9919, Val Acc: 0.1140\n",
      "Epoch 020, Loss: 0.0922, Acc: 1.0000, Val Loss: 1.5961, Val Acc: 0.4580\n",
      "Epoch 040, Loss: 0.0104, Acc: 1.0000, Val Loss: 1.7649, Val Acc: 0.4600\n",
      "Epoch 060, Loss: 0.0061, Acc: 1.0000, Val Loss: 1.7156, Val Acc: 0.4480\n",
      "Epoch 080, Loss: 0.0072, Acc: 1.0000, Val Loss: 1.5707, Val Acc: 0.4740\n",
      "Epoch 100, Loss: 0.0082, Acc: 1.0000, Val Loss: 1.4812, Val Acc: 0.4940\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b819ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4930\n"
     ]
    }
   ],
   "source": [
    "acc = mlp.test(data)\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51d24cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class  VanillaGNNLayer(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(dim_in, dim_out, bias = False)\n",
    "    \n",
    "    def forward(self, x, adjacency):\n",
    "        x = self.linear(x) #线性变换\n",
    "        x = torch.sparse.mm(adjacency, x) #邻接矩阵乘以特征矩阵\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf8d4430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "adjacency = to_dense_adj(data.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aabdaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h)\n",
    "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        h = self.gnn1(x, adjacency)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gnn2(h, adjacency)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x,adjacency)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, adjacency)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bde3ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=7, bias=False)\n",
      "  )\n",
      ")\n",
      "Epoch 000, Loss: 2.2500, Acc: 0.1357, Val Loss: 2.1049, Val Acc: 0.2380\n",
      "Epoch 020, Loss: 0.1315, Acc: 1.0000, Val Loss: 1.4412, Val Acc: 0.6860\n",
      "Epoch 040, Loss: 0.0218, Acc: 1.0000, Val Loss: 1.7630, Val Acc: 0.7340\n",
      "Epoch 060, Loss: 0.0091, Acc: 1.0000, Val Loss: 1.9079, Val Acc: 0.7380\n",
      "Epoch 080, Loss: 0.0057, Acc: 1.0000, Val Loss: 1.9354, Val Acc: 0.7420\n",
      "Epoch 100, Loss: 0.0043, Acc: 1.0000, Val Loss: 1.9290, Val Acc: 0.7360\n",
      "Test Accuracy: 0.7440\n"
     ]
    }
   ],
   "source": [
    "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(gnn)\n",
    "gnn.fit(data, epochs=100)\n",
    "acc = gnn.test(data)\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e1d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
